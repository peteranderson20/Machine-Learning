{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b72df611-ccd7-4cfa-a006-386514ba6918",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "- .gz: compressed CSVs with no header, so I will need to provide column names from kddcup.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c049874-9957-4cd3-ba4c-2a02c7530312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 2, 'name': 'Adult', 'repository_url': 'https://archive.ics.uci.edu/dataset/2/adult', 'data_url': 'https://archive.ics.uci.edu/static/public/2/data.csv', 'abstract': 'Predict whether annual income of an individual exceeds $50K/yr based on census data. Also known as \"Census Income\" dataset. ', 'area': 'Social Science', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 48842, 'num_features': 14, 'feature_types': ['Categorical', 'Integer'], 'demographics': ['Age', 'Income', 'Education Level', 'Other', 'Race', 'Sex'], 'target_col': ['income'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 1996, 'last_updated': 'Tue Sep 24 2024', 'dataset_doi': '10.24432/C5XW20', 'creators': ['Barry Becker', 'Ronny Kohavi'], 'intro_paper': None, 'additional_info': {'summary': \"Extraction was done by Barry Becker from the 1994 Census database.  A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\\n\\nPrediction task is to determine whether a person's income is over $50,000 a year.\\n\", 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Listing of attributes:\\r\\n\\r\\n>50K, <=50K.\\r\\n\\r\\nage: continuous.\\r\\nworkclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\\r\\nfnlwgt: continuous.\\r\\neducation: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\\r\\neducation-num: continuous.\\r\\nmarital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\\r\\noccupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\\r\\nrelationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\\r\\nrace: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\\r\\nsex: Female, Male.\\r\\ncapital-gain: continuous.\\r\\ncapital-loss: continuous.\\r\\nhours-per-week: continuous.\\r\\nnative-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.', 'citation': None}}\n",
      "              name     role         type      demographic  \\\n",
      "0              age  Feature      Integer              Age   \n",
      "1        workclass  Feature  Categorical           Income   \n",
      "2           fnlwgt  Feature      Integer             None   \n",
      "3        education  Feature  Categorical  Education Level   \n",
      "4    education-num  Feature      Integer  Education Level   \n",
      "5   marital-status  Feature  Categorical            Other   \n",
      "6       occupation  Feature  Categorical            Other   \n",
      "7     relationship  Feature  Categorical            Other   \n",
      "8             race  Feature  Categorical             Race   \n",
      "9              sex  Feature       Binary              Sex   \n",
      "10    capital-gain  Feature      Integer             None   \n",
      "11    capital-loss  Feature      Integer             None   \n",
      "12  hours-per-week  Feature      Integer             None   \n",
      "13  native-country  Feature  Categorical            Other   \n",
      "14          income   Target       Binary           Income   \n",
      "\n",
      "                                          description units missing_values  \n",
      "0                                                 N/A  None             no  \n",
      "1   Private, Self-emp-not-inc, Self-emp-inc, Feder...  None            yes  \n",
      "2                                                None  None             no  \n",
      "3    Bachelors, Some-college, 11th, HS-grad, Prof-...  None             no  \n",
      "4                                                None  None             no  \n",
      "5   Married-civ-spouse, Divorced, Never-married, S...  None             no  \n",
      "6   Tech-support, Craft-repair, Other-service, Sal...  None            yes  \n",
      "7   Wife, Own-child, Husband, Not-in-family, Other...  None             no  \n",
      "8   White, Asian-Pac-Islander, Amer-Indian-Eskimo,...  None             no  \n",
      "9                                       Female, Male.  None             no  \n",
      "10                                               None  None             no  \n",
      "11                                               None  None             no  \n",
      "12                                               None  None             no  \n",
      "13  United-States, Cambodia, England, Puerto-Rico,...  None            yes  \n",
      "14                                       >50K, <=50K.  None             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "adult = fetch_ucirepo(id=2) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = adult.data.features \n",
    "y = adult.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(adult.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(adult.variables) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414f9482-3d0e-4875-80bc-745d73098547",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec288416-405d-4912-a074-00d16c38653e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48842.000000</td>\n",
       "      <td>4.884200e+04</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.643585</td>\n",
       "      <td>1.896641e+05</td>\n",
       "      <td>10.078089</td>\n",
       "      <td>1079.067626</td>\n",
       "      <td>87.502314</td>\n",
       "      <td>40.422382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.710510</td>\n",
       "      <td>1.056040e+05</td>\n",
       "      <td>2.570973</td>\n",
       "      <td>7452.019058</td>\n",
       "      <td>403.004552</td>\n",
       "      <td>12.391444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.175505e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.781445e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.376420e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.490400e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "count  48842.000000  4.884200e+04   48842.000000  48842.000000  48842.000000   \n",
       "mean      38.643585  1.896641e+05      10.078089   1079.067626     87.502314   \n",
       "std       13.710510  1.056040e+05       2.570973   7452.019058    403.004552   \n",
       "min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.175505e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.781445e+05      10.000000      0.000000      0.000000   \n",
       "75%       48.000000  2.376420e+05      12.000000      0.000000      0.000000   \n",
       "max       90.000000  1.490400e+06      16.000000  99999.000000   4356.000000   \n",
       "\n",
       "       hours-per-week  \n",
       "count    48842.000000  \n",
       "mean        40.422382  \n",
       "std         12.391444  \n",
       "min          1.000000  \n",
       "25%         40.000000  \n",
       "50%         40.000000  \n",
       "75%         45.000000  \n",
       "max         99.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96549064-9423-4718-83be-10e1019122dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             48842 non-null  int64 \n",
      " 1   workclass       47879 non-null  object\n",
      " 2   fnlwgt          48842 non-null  int64 \n",
      " 3   education       48842 non-null  object\n",
      " 4   education-num   48842 non-null  int64 \n",
      " 5   marital-status  48842 non-null  object\n",
      " 6   occupation      47876 non-null  object\n",
      " 7   relationship    48842 non-null  object\n",
      " 8   race            48842 non-null  object\n",
      " 9   sex             48842 non-null  object\n",
      " 10  capital-gain    48842 non-null  int64 \n",
      " 11  capital-loss    48842 non-null  int64 \n",
      " 12  hours-per-week  48842 non-null  int64 \n",
      " 13  native-country  48568 non-null  object\n",
      "dtypes: int64(6), object(8)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f1415f1-3eac-42ca-a2f8-4a1a13e71ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   income  48842 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 381.7+ KB\n"
     ]
    }
   ],
   "source": [
    "y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9427ed0e-1ece-4496-9c5c-b5bf2412dc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>24720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       income\n",
       "count   48842\n",
       "unique      4\n",
       "top     <=50K\n",
       "freq    24720"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30ebb967-7ba4-476c-93cf-cbc1386996a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<=50K', '>50K', '<=50K.', '>50K.'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['income'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fb340e-6c28-4f22-9cf8-4c9730dce15d",
   "metadata": {},
   "source": [
    "'>50K' and '>50K.' is 1, '<=50K' and '<=50K.' is 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10a15ae1-8de7-4bb2-89de-024400664954",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, value in y['income'].items():\n",
    "    if value in ['<=50K', '<=50K.']:\n",
    "        y.at[idx, 'income'] = 0\n",
    "    else:\n",
    "        y.at[idx, 'income'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c57386c-1c71-4606-a734-dd41a5ccced0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['income'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70231042-97b2-432b-ab01-2b500aef8def",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/83/qx33zxpd4cjb39h49x9vvynr0000gn/T/ipykernel_26916/3755289315.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y['income'] = y['income'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "y['income'] = y['income'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e896636f-8b21-407c-b243-106de2352e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['income'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d48fcf2-6655-4d99-bbd6-a90b1ea86089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48842.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.239282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.426649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             income\n",
       "count  48842.000000\n",
       "mean       0.239282\n",
       "std        0.426649\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        0.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "448668a7-7fb9-46f4-a792-a3e0c92a28e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   income  48842 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 381.7 KB\n"
     ]
    }
   ],
   "source": [
    "y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01d27e90-042b-4c51-9625-42e9cd4261c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             48842 non-null  int64 \n",
      " 1   workclass       47879 non-null  object\n",
      " 2   fnlwgt          48842 non-null  int64 \n",
      " 3   education       48842 non-null  object\n",
      " 4   education-num   48842 non-null  int64 \n",
      " 5   marital-status  48842 non-null  object\n",
      " 6   occupation      47876 non-null  object\n",
      " 7   relationship    48842 non-null  object\n",
      " 8   race            48842 non-null  object\n",
      " 9   sex             48842 non-null  object\n",
      " 10  capital-gain    48842 non-null  int64 \n",
      " 11  capital-loss    48842 non-null  int64 \n",
      " 12  hours-per-week  48842 non-null  int64 \n",
      " 13  native-country  48568 non-null  object\n",
      "dtypes: int64(6), object(8)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c62ea5de-e6bf-46ae-859e-b1bb09642f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1221\n"
     ]
    }
   ],
   "source": [
    "num_rows_with_null = X.isnull().any(axis=1).sum()\n",
    "print(num_rows_with_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6aad4647-9968-42fc-9494-2f9219cf7d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(4262)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X == '?').sum().sum() #sum per column, total across all columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "364db5d3-3cb9-4648-aec1-80c2ec746c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3620\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X = X.replace('?', pd.NA)\n",
    "\n",
    "num_rows_with_null = X.isna().any(axis=1).sum()\n",
    "print(num_rows_with_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32c6c72e-bd0e-46a6-9551-8089d7d85cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['State-gov', 'Self-emp-not-inc', 'Private', 'Federal-gov',\n",
       "       'Local-gov', <NA>, 'Self-emp-inc', 'Without-pay', 'Never-worked',\n",
       "       nan], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['workclass'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768d1bd5-6e56-4d7c-a19e-0be042b82b24",
   "metadata": {},
   "source": [
    "Before we drop the missing rows, we want to see if there are alternative methods that could be better. First we will investigate if the missingness seems random or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2c5cb67-b9e8-4822-8175-fc53bd60e00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             48842 non-null  int64 \n",
      " 1   workclass       46043 non-null  object\n",
      " 2   fnlwgt          48842 non-null  int64 \n",
      " 3   education       48842 non-null  object\n",
      " 4   education-num   48842 non-null  int64 \n",
      " 5   marital-status  48842 non-null  object\n",
      " 6   occupation      46033 non-null  object\n",
      " 7   relationship    48842 non-null  object\n",
      " 8   race            48842 non-null  object\n",
      " 9   sex             48842 non-null  object\n",
      " 10  capital-gain    48842 non-null  int64 \n",
      " 11  capital-loss    48842 non-null  int64 \n",
      " 12  hours-per-week  48842 non-null  int64 \n",
      " 13  native-country  47985 non-null  object\n",
      "dtypes: int64(6), object(8)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00ad3b7f-430c-4b59-951c-9a5847d36611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "occupation        0.057512\n",
       "workclass         0.057307\n",
       "native-country    0.017546\n",
       "age               0.000000\n",
       "fnlwgt            0.000000\n",
       "education         0.000000\n",
       "education-num     0.000000\n",
       "marital-status    0.000000\n",
       "relationship      0.000000\n",
       "race              0.000000\n",
       "sex               0.000000\n",
       "capital-gain      0.000000\n",
       "capital-loss      0.000000\n",
       "hours-per-week    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets see % missingness in each column, random missingness should have the same % per column\n",
    "X.isnull().mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f06c966-a62d-40ef-89ab-d8f833ebe8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "occupation: p-value=0.0000\n",
      "workclass: p-value=0.0000\n",
      "native-country: p-value=0.2436\n"
     ]
    }
   ],
   "source": [
    "#this ues Chi-Squared test of indepdendence on a contingency table, \n",
    "#tells you whether two categorical variables are statistically independent\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "for col in [\"occupation\", \"workclass\", \"native-country\"]:\n",
    "    #builds a contingency table (frequency counts)\n",
    "    contingency = pd.crosstab(X[col].isnull(), y.squeeze())\n",
    "    chi2, p, _, _ = chi2_contingency(contingency)\n",
    "    print(f\"{col}: p-value={p:.4f}\")\n",
    "\n",
    "#if p < 0.05, missingness is statistically associated with the target \n",
    "#if p > 0.05, there's no strong evidence missingness depends on the target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a84a115-69a2-4caf-a2b9-d88a559cdbca",
   "metadata": {},
   "source": [
    "To deal with this, we will create a \"missing\" bucket for the embeddings since this statistical significance tells us that hte missingness is informative to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2e83fb6-bd71-487c-8e45-44b538c4b91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workclass: 10\n",
      "education: 16\n",
      "marital-status: 7\n",
      "occupation: 16\n",
      "relationship: 6\n",
      "race: 5\n",
      "sex: 2\n",
      "native-country: 43\n"
     ]
    }
   ],
   "source": [
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        print(f\"{column}: {len(X[column].unique())}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c4902c-5c8e-475c-bbad-a8900b766d0e",
   "metadata": {},
   "source": [
    "Checking for duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1d446c2-3fb9-42fc-998d-49f834bdeadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "num_duplicates = X.duplicated().sum()\n",
    "print(num_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0434407c-e032-4b3f-adfd-d331e19cd210",
   "metadata": {},
   "source": [
    "Checking how many times the same features map to different targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c5d27e6-bc3e-46a8-8e81-1616e04deebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conflicting feature sets: 5\n"
     ]
    }
   ],
   "source": [
    "#temp_df = X + y = features + target\n",
    "temp_df = X.copy()\n",
    "temp_df['target'] = y\n",
    "\n",
    "#list(X.columns) - gives a Python list of all feature column names\n",
    "#temp_df.groupby(list(X.columns)) - groups rows of temp_df by all their feature values\n",
    "#[\"target\"].nunique() - inside each group, look only at the target column and count \n",
    "    # how many unique target values there are\n",
    "#.reset_index() - by default groupby makes the grouping columns part of the index, not normal columns\n",
    "    # so reset_index() moves them abck into regular columns\n",
    "conflicts = (\n",
    "    temp_df.groupby(list(X.columns))[\"target\"].nunique().reset_index()\n",
    ")\n",
    "\n",
    "conflicts = conflicts[conflicts['target'] > 1]\n",
    "\n",
    "print(\"Number of conflicting feature sets:\", len(conflicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b13f020e-6b51-46d7-8dfc-355903a14ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             48842 non-null  int64 \n",
      " 1   workclass       46043 non-null  object\n",
      " 2   fnlwgt          48842 non-null  int64 \n",
      " 3   education       48842 non-null  object\n",
      " 4   education-num   48842 non-null  int64 \n",
      " 5   marital-status  48842 non-null  object\n",
      " 6   occupation      46033 non-null  object\n",
      " 7   relationship    48842 non-null  object\n",
      " 8   race            48842 non-null  object\n",
      " 9   sex             48842 non-null  object\n",
      " 10  capital-gain    48842 non-null  int64 \n",
      " 11  capital-loss    48842 non-null  int64 \n",
      " 12  hours-per-week  48842 non-null  int64 \n",
      " 13  native-country  47985 non-null  object\n",
      "dtypes: int64(6), object(8)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb27534-5ec8-4fb7-9086-0b2448c637e9",
   "metadata": {},
   "source": [
    "## Options for Encoding Categorical Variables\n",
    "1. One-Hot Encoding\n",
    "   - Pros: no information loss\n",
    "   - Cons: expldoes feature size, leads to sparse data\n",
    "2. Label Encoding\n",
    "   - How it works: Assign each category an integer label\n",
    "   - Pros: keeps dimensionality low\n",
    "   - Cons: NN may interpret numbers as ordinal when in reality they have no mathematical relationship\n",
    "3. Target Encoding / Mean Encoding\n",
    "   - How it works: Replaces each category with a numerical statistic, which could be the most common category\n",
    "   - Pros: compact\n",
    "   - Cons: loss of information\n",
    "4. Embedding Layers\n",
    "   - How it works: each category is mapped to a dense vector of learned weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac056dd5-09b1-4bfd-8ecc-01042a723ff6",
   "metadata": {},
   "source": [
    "Dropping rows for SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bb8f486d-8805-473f-8efd-5982e50526f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (45222, 14)\n",
      "y (45222, 1)\n"
     ]
    }
   ],
   "source": [
    "X = X.dropna()\n",
    "y = y.loc[X.index]\n",
    "print(\"X\", X.shape)\n",
    "print('y', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6973890-97f8-4603-b74c-7f51fb59d9bd",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "- We already handled missing data, and categorical data will be handled when we setup the model since there will be an embedding layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b213d632-dc48-4eb8-adc8-8d467ada8093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "cat_cols = [c for c in X.columns if X[c].dtype == 'object']\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_train_full\n",
    ")\n",
    "\n",
    "\n",
    "#stratification to y to make sure distribution of classes is the same in train and validaiton. \n",
    "\n",
    "\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e0113c-e429-4a2f-a192-8048997cbb11",
   "metadata": {},
   "source": [
    "## SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1b886c97-6655-4828-8ae8-2fac607080e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_tr = X_train.copy()\n",
    "y_tr = y_train.copy()\n",
    "\n",
    "cats_lookup = {} #storing category lists to invert codes later\n",
    "for column in cat_cols:\n",
    "    cat = pd.Categorical(X_tr[column])\n",
    "    cats_lookup[column] = cat.categories\n",
    "    X_tr[column] = cat.codes #integer codes\n",
    "\n",
    "all_cols = list(X_tr.columns)\n",
    "cat_idx = [all_cols.index(c) for c in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9e2df571-e447-4e16-9766-f29b4588d750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "sm = SMOTENC(\n",
    "    categorical_features=cat_idx,\n",
    "    sampling_strategy=\"auto\",\n",
    "    k_neighbors=5,\n",
    "    random_state=42\n",
    ")\n",
    "X_tr_res, y_tr_res = sm.fit_resample(X_tr.values, np.asarray(y_tr).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "16e92389-cca9-4c83-873f-70d8888740b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_res = pd.DataFrame(X_tr_res, columns=all_cols)\n",
    "y_train_res = pd.Series(y_tr_res, index=range(len(y_tr_res)))\n",
    "\n",
    "for column in cat_cols:\n",
    "    codes = X_train_res[column].astype(int).to_numpy()\n",
    "    X_train_res[column] = pd.Series(cats_lookup[column].take(codes), index=X_train_res.index).astype(\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "85c2d07d-c766-4062-a981-0a9612eb6b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: {(0,): 21768, (1,): 7173}\n",
      "After : {1: 21768, 0: 21768}\n"
     ]
    }
   ],
   "source": [
    "print(\"Before:\", y_train.value_counts().to_dict())\n",
    "print(\"After :\", y_train_res.value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9bc3ff33-5567-4520-92c0-ecfafff648e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43536, 14) (43536,)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train_res\n",
    "y_train = y_train_res\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec567e5-11e6-4179-8f72-c5a3342b983e",
   "metadata": {},
   "source": [
    "### Converting categorical columns to integer IDS\n",
    "\n",
    "Embedding layers expect integer indices, so the categories must be mapped to numbers with 0 reserved for UNK (unknown/unseen categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "13116afc-2c85-4b13-b8d3-fa063bc31427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'workclass': {'__UNK__': 0, '__MISSING__': 1, 'Private': 2, 'State-gov': 3, 'Self-emp-not-inc': 4, 'Federal-gov': 5, 'Local-gov': 6, 'Self-emp-inc': 7, 'Without-pay': 8}, 'education': {'__UNK__': 0, '__MISSING__': 1, 'Bachelors': 2, 'HS-grad': 3, 'Masters': 4, 'Some-college': 5, '7th-8th': 6, 'Prof-school': 7, '11th': 8, '10th': 9, 'Assoc-voc': 10, '5th-6th': 11, '12th': 12, 'Assoc-acdm': 13, '9th': 14, 'Doctorate': 15, '1st-4th': 16, 'Preschool': 17}, 'marital-status': {'__UNK__': 0, '__MISSING__': 1, 'Married-civ-spouse': 2, 'Never-married': 3, 'Divorced': 4, 'Separated': 5, 'Widowed': 6, 'Married-spouse-absent': 7, 'Married-AF-spouse': 8}, 'occupation': {'__UNK__': 0, '__MISSING__': 1, 'Exec-managerial': 2, 'Adm-clerical': 3, 'Prof-specialty': 4, 'Sales': 5, 'Farming-fishing': 6, 'Machine-op-inspct': 7, 'Transport-moving': 8, 'Craft-repair': 9, 'Tech-support': 10, 'Other-service': 11, 'Protective-serv': 12, 'Priv-house-serv': 13, 'Handlers-cleaners': 14, 'Armed-Forces': 15}, 'relationship': {'__UNK__': 0, '__MISSING__': 1, 'Husband': 2, 'Unmarried': 3, 'Own-child': 4, 'Other-relative': 5, 'Wife': 6, 'Not-in-family': 7}, 'race': {'__UNK__': 0, '__MISSING__': 1, 'White': 2, 'Black': 3, 'Other': 4, 'Asian-Pac-Islander': 5, 'Amer-Indian-Eskimo': 6}, 'sex': {'__UNK__': 0, '__MISSING__': 1, 'Male': 2, 'Female': 3}, 'native-country': {'__UNK__': 0, '__MISSING__': 1, 'United-States': 2, 'Cuba': 3, 'Dominican-Republic': 4, 'India': 5, 'Italy': 6, 'Canada': 7, 'China': 8, 'Guatemala': 9, 'Japan': 10, 'Ecuador': 11, 'Vietnam': 12, 'Mexico': 13, 'Philippines': 14, 'Puerto-Rico': 15, 'England': 16, 'Jamaica': 17, 'El-Salvador': 18, 'South': 19, 'Poland': 20, 'Taiwan': 21, 'Germany': 22, 'Portugal': 23, 'Iran': 24, 'Peru': 25, 'Trinadad&Tobago': 26, 'Nicaragua': 27, 'France': 28, 'Haiti': 29, 'Ireland': 30, 'Columbia': 31, 'Greece': 32, 'Yugoslavia': 33, 'Outlying-US(Guam-USVI-etc)': 34, 'Thailand': 35, 'Scotland': 36, 'Cambodia': 37, 'Hong': 38, 'Hungary': 39, 'Laos': 40, 'Honduras': 41, 'Holand-Netherlands': 42}}\n",
      "9\n",
      "18\n",
      "9\n",
      "16\n",
      "8\n",
      "7\n",
      "4\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "#first we build the mappings from the training dataset only\n",
    "cat_maps = {}\n",
    "\n",
    "for column in cat_cols:\n",
    "    updated_column = X_train[column].astype(\"object\").fillna(\"__MISSING__\")\n",
    "    categories = updated_column.unique()\n",
    "    mapping = {\"__UNK__\": 0, \"__MISSING__\": 1}\n",
    "    next_id = 2\n",
    "    for v in categories:\n",
    "        if v in mapping: \n",
    "            continue\n",
    "        mapping[v] = next_id\n",
    "        next_id += 1\n",
    "    cat_maps[column] = mapping\n",
    "\n",
    "print(cat_maps)\n",
    "\n",
    "for c in cat_cols:\n",
    "    print(len(cat_maps[c]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1bd56542-0f0c-4610-acb7-10afcf9597b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "        workclass  education  marital-status  occupation  relationship  race  \\\n",
      "0              2          2               2           2             2     2   \n",
      "1              3          3               3           3             3     3   \n",
      "2              2          4               2           4             2     2   \n",
      "3              4          5               2           5             2     2   \n",
      "4              2          5               3           3             4     2   \n",
      "...          ...        ...             ...         ...           ...   ...   \n",
      "43531          2          2               2           2             2     2   \n",
      "43532          2          3               2           2             2     2   \n",
      "43533          2          4               2          10             2     2   \n",
      "43534          2          3               2           9             2     2   \n",
      "43535          2         13               2           9             2     2   \n",
      "\n",
      "       sex  native-country  \n",
      "0        2               2  \n",
      "1        3               2  \n",
      "2        2               3  \n",
      "3        2               2  \n",
      "4        3               2  \n",
      "...    ...             ...  \n",
      "43531    2               2  \n",
      "43532    2               2  \n",
      "43533    2               2  \n",
      "43534    2               2  \n",
      "43535    2               2  \n",
      "\n",
      "[43536 rows x 8 columns]\n",
      "\n",
      "Val:\n",
      "        workclass  education  marital-status  occupation  relationship  race  \\\n",
      "15244          2          5               2           5             2     2   \n",
      "26994          2          3               2           7             2     2   \n",
      "23561          2          3               5           3             3     2   \n",
      "17681          2          5               3           5             7     2   \n",
      "45343          2          5               3           8             7     2   \n",
      "...          ...        ...             ...         ...           ...   ...   \n",
      "46688          2          6               3          14             4     2   \n",
      "8863           2          3               5           9             7     2   \n",
      "12138          6          3               3          11             3     2   \n",
      "14639          2          2               3           2             7     2   \n",
      "28779          2          9               3           5             7     2   \n",
      "\n",
      "       sex  native-country  \n",
      "15244    2               2  \n",
      "26994    2               2  \n",
      "23561    3               2  \n",
      "17681    2               2  \n",
      "45343    2               2  \n",
      "...    ...             ...  \n",
      "46688    2               2  \n",
      "8863     2               2  \n",
      "12138    3               2  \n",
      "14639    2               2  \n",
      "28779    3               2  \n",
      "\n",
      "[7236 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "def map_categories(column, mapping):\n",
    "    column = column.astype(\"object\").fillna(\"__MISSING__\")\n",
    "    return column.map(mapping).fillna(mapping[\"__UNK__\"]).astype(\"int64\")\n",
    "\n",
    "# I removed missing columns from X already, but here\n",
    "# map(mapping) will return NaN if it encounters a category not seen in cat_maps\n",
    "# that is, not seen in training but seen in the validation set\n",
    "# so, I put fillna(0) to put those unseen cateogires into the unk bucket\n",
    "\n",
    "\n",
    "#the map_categories function only works on one column at a time,\n",
    "#so I put a lambda function so it applies map_categories to all columns in cat_cols\n",
    "\n",
    "train_categories = X_train[cat_cols].apply(lambda column: map_categories(column, cat_maps[column.name]))\n",
    "val_categories = X_val[cat_cols].apply(lambda column: map_categories(column, cat_maps[column.name]))\n",
    "\n",
    "print(\"Train:\\n\", train_categories)\n",
    "print(\"\\nVal:\\n\", val_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a58cce-2e27-49a0-8bbd-ce969cd5546e",
   "metadata": {},
   "source": [
    "### Scaling the numeric columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ed9fe5d2-25b1-4e14-9e7b-c2263fe179bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#standard scaler transforms integers into real numbers\n",
    "#PyTorch layers expect inputs of type torch.float32\n",
    "#It is float32 instead of float64 to use less memory, therefore the training process is faster\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[num_cols]).astype(\"float32\")\n",
    "X_val_scaled = scaler.transform(X_val[num_cols]).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd572e2e-511c-48ff-a5fe-53da63975c9c",
   "metadata": {},
   "source": [
    "### Building categorical ID matrices\n",
    "This step is about converting the categorical columns into the shape that that the embedding layers expect, which is (batch_size, num_cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5c391a1b-fb33-4783-aa0f-275ea5b92ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43536, 8)\n",
      "[[2 2 2 2 2 2 2 2]\n",
      " [3 3 3 3 3 3 3 2]\n",
      " [2 4 2 4 2 2 2 3]]\n"
     ]
    }
   ],
   "source": [
    "X_train_categories = train_categories.to_numpy(dtype=\"int64\")\n",
    "X_val_categories = val_categories.to_numpy(dtype=\"int64\")\n",
    "\n",
    "print(X_train_categories.shape) #(num_rows, num_cat_cols)\n",
    "print(X_train_categories[:3]) #each row = one training example\n",
    "                              #each column = one encoded ID for a categorical feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f779b2-8716-4a03-ac43-eec2a274f30c",
   "metadata": {},
   "source": [
    "### Make y float32\n",
    "- We will be using nn.BCEWithLogitsLoss\n",
    "- The model will output a float32 logit\n",
    "- The loss compares that float32 logit against the target tensor (y), and if y is int, PyTorch will throw a dtype mismatch error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "502a8bdd-6680-42cc-a0d3-ef0f2da5c2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "76177e1d-09ca-4c34-9708-b57c48501230",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_array = y_train.astype(\"float32\").to_numpy()\n",
    "y_val_array = y_val.astype(\"float32\").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3cd751c2-46be-4fa0-b346-ac4cb9c50c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_train_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbac700-eaeb-4bc0-bf5a-b23710771e86",
   "metadata": {},
   "source": [
    "### The Embedding Layer\n",
    "- Mathematically: a lookup table (a matrix of learnable weights)\n",
    "- Shape: (num_categories, embedding_dim); the rows are categories (0, 1, 2, etc.) and the columns are the latent features for each category. So, each categorical column will get its own embedding layer.\n",
    "- It expects a tensor of integer IDs (torch.int64 aka LongTensor) of shape (batch_size, num_cat_cols). Each row is a sample, each column is the category (integer IDs)\n",
    "- For each categorical column it outputs an embedding vector as float32. For multiple categorical columns, their embeddings will be contatenated.\n",
    "- The embedding vectors themselves are learned during training\n",
    "\n",
    "\n",
    "<br>\n",
    "In short: column --> embedding vector \n",
    "<br>\n",
    "The next step will be figuring out how many categories each column has, then picking embedding dimensions for each. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c453adac-fd50-4708-a1ee-09c8d3313fbd",
   "metadata": {},
   "source": [
    "### Vocab sizes \n",
    "The cleanest, stable vocab size is just the mapping length, or the toal number of unique integer IDs that can appear in a given column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ba0308d1-0351-490a-9e2f-27e5ac0c312a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_sizes [9, 18, 9, 16, 8, 7, 4, 43]\n",
      "emb_dims [(9, 14), (18, 16), (9, 14), (16, 16), (8, 13), (7, 13), (4, 11), (43, 20)]\n"
     ]
    }
   ],
   "source": [
    "vocab_sizes = [len(cat_maps[c]) for c in cat_cols]\n",
    "\n",
    "#next, we have a function that computes the embedding dimension\n",
    "#in a way that balances model expressiveness with efficiency\n",
    "\n",
    "def pick_emb_dim(vocab_size):\n",
    "    return min(50, max(4, int(round(vocab_size**0.25 * 8))))\n",
    "\n",
    "#Next we compute the embedding dimensions for each column\n",
    "emb_dims = [(vocab_size, pick_emb_dim(vocab_size)) for vocab_size in vocab_sizes]\n",
    "\n",
    "print(\"vocab_sizes\", vocab_sizes)\n",
    "print(\"emb_dims\", emb_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522db6a1-cb8e-4922-92e4-261666cd1e17",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "This part of the project is where the PyTorch philosphy shines.\n",
    "- Nothing is hidden, and I define how data is stored, accessed, batched, and shuffled.\n",
    "\n",
    "For this, PyTorch gives two pieces:\n",
    "1. Dataset: how to get a single sample, and we can neatly package each batch as (x_cats, x_nums, y)\n",
    "2. DataLoader: how to turn that Dataset into batches with shuffling, batching, multiprocessing, moving to GPU, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2c5c0d-51b4-42a9-a5fa-c0479904b92c",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "17c899ae-ed3f-407b-9578-434470434bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class TabularDS(Dataset):\n",
    "    def __init__(self, X_cats, X_nums, y):\n",
    "        self.X_cats = X_cats\n",
    "        self.X_nums = X_nums\n",
    "        self.y = y.reshape(-1, 1) #forces column vector (N,1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (\n",
    "            torch.tensor(self.X_cats[i], dtype=torch.long),\n",
    "            torch.tensor(self.X_nums[i], dtype=torch.float32),\n",
    "            torch.tensor(self.y[i], dtype=torch.float32),\n",
    "        )\n",
    "train_dataset = TabularDS(X_train_categories, X_train_scaled, y_train_array)\n",
    "val_dataset = TabularDS(X_val_categories, X_val_scaled, y_val_array)\n",
    "\n",
    "#smaller batch size for training batches helps the optimizer see more gradient noise,\n",
    "#improving generalization\n",
    "#in validation, we aren't updating any weights so higher batch size means faster evaluation\n",
    "#in addition, we shuffle the training set so the model doesn't overfit to the order in the data\n",
    "#we set shuffling to false for validation loader as it provides no benefit \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db29453c-ae44-4d8a-ab9d-c158fbefde00",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "13aeeda2-fbf9-45ff-9478-73f12d440de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CatEmbMLP(nn.Module):\n",
    "    #hidden=(128, 64) means first linear layer is 128 units and second linear layer is 64\n",
    "    def __init__(self, emb_dims, n_num, hidden = (256, 128, 64), p=0):\n",
    "        super().__init__()\n",
    "        #for each categorical column, build one embedding table\n",
    "        #v = vocab size (number of categories)\n",
    "        #d = embedding dimension (chosen earlier)\n",
    "        self.embs = nn.ModuleList([nn.Embedding(v, d) for (v, d) in emb_dims])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "\n",
    "        #emb_dims is of shape (vocab_sizei, emb_dimi)\n",
    "        #the next line refers to the total embedding output size\n",
    "        #n_num is the amount of numerical columns\n",
    "        in_dim = sum(d for _, d in emb_dims) + n_num\n",
    "        layers = []\n",
    "        for h in hidden:\n",
    "            layers += [\n",
    "                nn.Linear(in_dim, h), \n",
    "                nn.BatchNorm1d(h),\n",
    "                nn.LeakyReLU(), \n",
    "                nn.Dropout(p)]\n",
    "            in_dim = h #reset the input dimensions \n",
    "        layers += [nn.Linear(in_dim, 1)] #binary logit\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    #x_cat: categorical input tensor\n",
    "        #shape: (batch_size, n_cat_cols)\n",
    "        #dtype: torch.int64 (LongTensor)\n",
    "    #x_num: numeric input tensor\n",
    "        #shape: (batch_size, n_num_cols)\n",
    "        #dtype: torch.float32\n",
    "    def forward(self, x_cat, x_num):\n",
    "        #x_cat[:, i] = all IDs for column i in the batch --> shape (batch_size,)\n",
    "        #emb(x_cat[:, i]) = look up each IDs embedding vector --> shape (batch_size, emb_dim_i)\n",
    "        #emb_list collects these embeddings in a list \n",
    "        emb_list = [emb(x_cat[:, i]) for i, emb in enumerate(self.embs)]\n",
    "        #join the embedding vectors side by side --> (batch_size, sum_of_all_emb_dims)\n",
    "        x = torch.cat(emb_list, dim=1)\n",
    "        #applying dropout for regularization, preventing overfitting to rare cetegories\n",
    "        x = self.emb_drop(x)\n",
    "        #join with numeric features, shape (batch_size, sum_emb_dims + n_num) as defined in __init__\n",
    "        x = torch.cat([x, x_num], dim=1)\n",
    "        #forward pass through the mlp\n",
    "        return self.mlp(x)\n",
    "\n",
    "#seeing if we can take advantage of Apple Silicon GPU \n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "n_num = X_train_scaled.shape[1]\n",
    "model = CatEmbMLP(emb_dims, n_num, hidden=(128, 64), p=0.1).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b2222d-6eef-41a8-896a-1248eda8ea7a",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca36fbf-16da-4eb5-89e2-4d9d9aadc988",
   "metadata": {},
   "source": [
    "### Improvements. \n",
    "\n",
    "**Run 1**\n",
    "Epoch 001 | train 0.3054 | val 0.3064 | acc 0.861 | auc 0.916 | lr 2.0e-04\n",
    "Epoch 002 | train 0.3034 | val 0.3067 | acc 0.861 | auc 0.916 | lr 2.0e-04\n",
    "Epoch 003 | train 0.3048 | val 0.3070 | acc 0.860 | auc 0.915 | lr 2.0e-04\n",
    "Epoch 004 | train 0.3039 | val 0.3071 | acc 0.860 | auc 0.915 | lr 2.0e-04\n",
    "Epoch 005 | train 0.3039 | val 0.3073 | acc 0.860 | auc 0.915 | lr 1.0e-04\n",
    "Epoch 006 | train 0.3034 | val 0.3073 | acc 0.860 | auc 0.915 | lr 1.0e-04\n",
    "Epoch 007 | train 0.3038 | val 0.3073 | acc 0.860 | auc 0.915 | lr 1.0e-04\n",
    "Epoch 008 | train 0.3027 | val 0.3074 | acc 0.859 | auc 0.915 | lr 1.0e-04\n",
    "Epoch 009 | train 0.3022 | val 0.3074 | acc 0.860 | auc 0.915 | lr 5.0e-05\n",
    "Epoch 010 | train 0.3024 | val 0.3074 | acc 0.860 | auc 0.915 | lr 5.0e-05\n",
    "Epoch 011 | train 0.3028 | val 0.3075 | acc 0.859 | auc 0.915 | lr 5.0e-05\n",
    "Early stopping at epoch 11 (best val loss: 0.3064)\n",
    "Loaded best model (val loss = 0.3064 )\n",
    "\n",
    "- it seems that train accuracy ~= val accuracy, but since they increase very little over epochs it seems like the model isn't learning very much \n",
    "- To compare, we could run XGBoost.\n",
    "\n",
    "**Run 2**\n",
    "Here, I will try variance depth and width of the neural network while implementing regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2a848191-13de-47cc-ba9d-187ca41134ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train loss 0.4716 | val loss 0.4337 | acc 0.774 | auc 0.870 | lr 2.0e-04\n",
      "Epoch 002 | train loss 0.3680 | val loss 0.3918 | acc 0.806 | auc 0.885 | lr 2.0e-04\n",
      "Epoch 003 | train loss 0.3450 | val loss 0.3760 | acc 0.820 | auc 0.892 | lr 2.0e-04\n",
      "Epoch 004 | train loss 0.3346 | val loss 0.3818 | acc 0.818 | auc 0.895 | lr 2.0e-04\n",
      "Epoch 005 | train loss 0.3285 | val loss 0.3797 | acc 0.821 | auc 0.897 | lr 2.0e-04\n",
      "Epoch 006 | train loss 0.3230 | val loss 0.3748 | acc 0.825 | auc 0.899 | lr 2.0e-04\n",
      "Epoch 007 | train loss 0.3186 | val loss 0.3691 | acc 0.829 | auc 0.901 | lr 2.0e-04\n",
      "Epoch 008 | train loss 0.3153 | val loss 0.3597 | acc 0.830 | auc 0.904 | lr 2.0e-04\n",
      "Epoch 009 | train loss 0.3101 | val loss 0.3776 | acc 0.822 | auc 0.903 | lr 2.0e-04\n",
      "Epoch 010 | train loss 0.3067 | val loss 0.3683 | acc 0.826 | auc 0.906 | lr 2.0e-04\n",
      "Epoch 011 | train loss 0.3044 | val loss 0.3597 | acc 0.831 | auc 0.906 | lr 2.0e-04\n",
      "Epoch 012 | train loss 0.3028 | val loss 0.3624 | acc 0.830 | auc 0.907 | lr 2.0e-05\n",
      "Epoch 013 | train loss 0.2999 | val loss 0.3510 | acc 0.836 | auc 0.907 | lr 2.0e-05\n",
      "Epoch 014 | train loss 0.3003 | val loss 0.3542 | acc 0.833 | auc 0.907 | lr 2.0e-05\n",
      "Epoch 015 | train loss 0.2986 | val loss 0.3733 | acc 0.825 | auc 0.907 | lr 2.0e-05\n",
      "Epoch 016 | train loss 0.2977 | val loss 0.3577 | acc 0.833 | auc 0.908 | lr 2.0e-05\n",
      "Epoch 017 | train loss 0.2990 | val loss 0.3574 | acc 0.833 | auc 0.908 | lr 1.0e-05\n",
      "Epoch 018 | train loss 0.2979 | val loss 0.3660 | acc 0.829 | auc 0.908 | lr 1.0e-05\n",
      "Epoch 019 | train loss 0.2983 | val loss 0.3543 | acc 0.835 | auc 0.908 | lr 1.0e-05\n",
      "Epoch 020 | train loss 0.2986 | val loss 0.3685 | acc 0.829 | auc 0.908 | lr 1.0e-05\n",
      "Epoch 021 | train loss 0.2982 | val loss 0.3603 | acc 0.832 | auc 0.908 | lr 1.0e-05\n",
      "Epoch 022 | train loss 0.2988 | val loss 0.3582 | acc 0.832 | auc 0.908 | lr 1.0e-05\n",
      "Epoch 023 | train loss 0.2980 | val loss 0.3641 | acc 0.829 | auc 0.908 | lr 1.0e-05\n",
      "Early stopping at epoch 23 (best val loss: 0.3510)\n",
      "Loaded best model (val loss = 0.3510 )\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "#I had problems using mps so switched to cpu. \n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss, Optimizer, Scheduler \n",
    "criterion = nn.BCEWithLogitsLoss() #binary cross entropy\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
    "\n",
    "#if a metric (validation loss below) doesn't improve after 3 epochs, reduce learning rate\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.1, patience=3, min_lr=1e-5\n",
    ")\n",
    "\n",
    "# One training epoch\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train() #in PyTorch there is train and eval modes \n",
    "    total_loss, total_n = 0.0, 0\n",
    "    for x_cat, x_num, yb in loader:\n",
    "        #PyTorch tensors must live on the same device as the model to interact\n",
    "        #non_blocking isn't really relevant unless using GPU\n",
    "        x_cat = x_cat.to(device, non_blocking=True)\n",
    "        x_num = x_num.to(device, non_blocking=True)\n",
    "        yb    = yb.to(device, non_blocking=True) #shape (batch_size, 1)\n",
    "\n",
    "        logits = model(x_cat, x_num) #calls the forward function of the model           \n",
    "        loss = criterion(logits, yb) #computing loss\n",
    "\n",
    "        #clears old gradients from previous step (PyTorch accumulates gradients)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        #PyTorch computes gradient of loss w respect to each parameter by applying\n",
    "        #the chain rule through the computation graph\n",
    "        #every parameter at the end has a .grad tensor attached\n",
    "        loss.backward()\n",
    "        #rescales the gradients if their norm exceeds 1.0 preventing exploding gradients\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        #optimizer updates the parameters using the stored .grad rules\n",
    "        #for adamw, this means it does adaptive learning rate calculation + weight decay\n",
    "        # + correction before applying the update\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_size = yb.size(0) #gives number of rows \n",
    "        total_loss += loss.item() * batch_size #sum of losses per batch\n",
    "        total_n += batch_size\n",
    "    return total_loss / total_n #epoch wide mean loss \n",
    "\n",
    "# Validation pass \n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval() #put the model in eval mode \n",
    "    total_loss, total_n = 0.0, 0\n",
    "    all_probs, all_targets = [], []\n",
    "\n",
    "    for x_cat, x_num, yb in loader:\n",
    "        x_cat = x_cat.to(device, non_blocking=True)\n",
    "        x_num = x_num.to(device, non_blocking=True)\n",
    "        yb    = yb.to(device, non_blocking=True)\n",
    "\n",
    "        logits = model(x_cat, x_num)\n",
    "        loss = criterion(logits, yb)\n",
    "\n",
    "        bs = yb.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        total_n += bs\n",
    "\n",
    "        #converts to probabilities, moves off gpu if using it, and converts to numpy array\n",
    "        #for scikit-learn metrics \n",
    "        probs = torch.sigmoid(logits).squeeze(1).cpu().numpy()\n",
    "        targets = yb.squeeze(1).cpu().numpy() #makes it (batch_size,)\n",
    "        all_probs.append(probs)\n",
    "        all_targets.append(targets)\n",
    "\n",
    "    import numpy as np\n",
    "    all_probs   = np.concatenate(all_probs, axis=0).reshape(-1)     # 1-D\n",
    "    all_targets = np.concatenate(all_targets, axis=0).reshape(-1)   # 1-D\n",
    "\n",
    "    # (optional) mask out any non-finite values, just in case\n",
    "    m = np.isfinite(all_probs) & np.isfinite(all_targets)\n",
    "    all_probs, all_targets = all_probs[m], all_targets[m]\n",
    "\n",
    "    # preds as integers (0/1)\n",
    "    preds = (all_probs >= 0.5).astype(np.int32)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "    acc = accuracy_score(all_targets, preds)\n",
    "\n",
    "    # auc only if both classes present\n",
    "    if np.unique(all_targets).size > 1:\n",
    "        auc = roc_auc_score(all_targets, all_probs)\n",
    "    else:\n",
    "        auc = float(\"nan\")\n",
    "\n",
    "    return (total_loss / total_n), acc, auc\n",
    "\n",
    "# Training loop with early stopping \n",
    "EPOCHS    = 200            \n",
    "PATIENCE  = 10             \n",
    "MIN_DELTA = 1e-4        \n",
    "\n",
    "best_val = float(\"inf\")\n",
    "patience_ctr = 0\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    tr_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    va_loss, va_acc, va_auc = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "    #step scheduler on val loss\n",
    "    scheduler.step(va_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch:03d} | \"\n",
    "          f\"train loss {tr_loss:.4f} | val loss {va_loss:.4f} | acc {va_acc:.3f} | auc {va_auc:.3f} | \"\n",
    "          f\"lr {optimizer.param_groups[0]['lr']:.1e}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if va_loss < best_val - MIN_DELTA:\n",
    "        best_val = va_loss\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "        patience_ctr = 0\n",
    "    else:\n",
    "        patience_ctr += 1\n",
    "        if patience_ctr >= PATIENCE:\n",
    "            print(f\"Early stopping at epoch {epoch} (best val loss: {best_val:.4f})\")\n",
    "            break\n",
    "\n",
    "# restoring best weights \n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "    model.to(device)\n",
    "    print(\"Loaded best model (val loss =\", f\"{best_val:.4f}\", \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39608f36-b6bd-41bc-b9ac-71052b74b7c0",
   "metadata": {},
   "source": [
    "## XGBoost Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "55f3b3a5-596b-4956-96b4-09e7414d6598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.924  ACC: 0.863  Best trees: 554\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.callback import EarlyStopping\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "X_train_xgb = X_train.copy()\n",
    "X_val_xgb = X_val.copy()\n",
    "\n",
    "for categorical in cat_cols:\n",
    "    X_train_xgb[categorical] = X_train_xgb[categorical].astype(\"category\")\n",
    "    X_val_xgb[categorical] = pd.Categorical(X_val_xgb[categorical], categories=X_train_xgb[categorical].cat.categories)\n",
    "\n",
    "#Building DMatrices with native categorical support\n",
    "dtrain = xgb.DMatrix(X_train_xgb, label=y_train, enable_categorical=True)\n",
    "dval   = xgb.DMatrix(X_val_xgb,   label=y_val,   enable_categorical=True)\n",
    "\n",
    "#Params \n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"logloss\",    \n",
    "    \"max_depth\": 6,\n",
    "    \"eta\": 0.03,              \n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"lambda\": 1.0,            \n",
    "    \"alpha\": 0.0,              \n",
    "    \"tree_method\": \"hist\",\n",
    "    \"verbosity\": 0,\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "#Train with early stopping on validation\n",
    "evals = [(dval, \"val\")]\n",
    "bst = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=2000,\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=50,   \n",
    "    verbose_eval=False,\n",
    ")\n",
    "\n",
    "#Evaluate\n",
    "probs = bst.predict(dval)   # probabilities for positive class\n",
    "preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "auc = roc_auc_score(y_val, probs)\n",
    "acc = accuracy_score(y_val, preds)\n",
    "\n",
    "print(f\"AUC: {auc:.3f}  ACC: {acc:.3f}  Best trees: {bst.best_iteration}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fc1c29-fd35-44c4-8e1c-aefe2de180d3",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c06eb175-6dc4-4f25-bb27-5b83ed6e4827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 18:21:18,100] A new study created in memory with name: no-name-430670de-798a-48bc-99f6-32632d3d5555\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df86b07a51c240ae94a5a12ffc700052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 18:21:35,008] Trial 0 finished with value: 0.3391857347216904 and parameters: {'batch_size': 512, 'emb_dim_scale': 1.0493292420985183, 'n_layers': 2, 'width0': 512, 'width1': 512, 'activation': 'ReLU', 'use_bn': True, 'use_residuals': False, 'dropout_mlp': 0.14561457009902096, 'dropout_emb': 0.18355586841671384, 'optimizer': 'RMSprop', 'lr': 0.000471705203762518, 'weight_decay_mlp': 0.00013157287601765622, 'weight_decay_emb': 3.972110727381914e-07, 'adam_beta2': 0.975197487482267, 'adam_eps': 1.530485212183145e-07, 'lr_factor': 0.3185801650879991, 'lr_patience': 5, 'clip_norm': 0.7557861855309373, 'label_smoothing': 0.006505159298527952}. Best is trial 0 with value: 0.3391857347216904.\n",
      "[I 2025-08-21 18:21:46,242] Trial 1 finished with value: 0.3750989629360376 and parameters: {'batch_size': 512, 'emb_dim_scale': 0.9023068845866853, 'n_layers': 2, 'width0': 128, 'width1': 256, 'activation': 'ReLU', 'use_bn': False, 'use_residuals': False, 'dropout_mlp': 0.46974947078209456, 'dropout_emb': 0.26844820512829465, 'optimizer': 'Adam', 'lr': 0.0001947558230629544, 'weight_decay_mlp': 1.3245461546001878e-06, 'weight_decay_emb': 9.462175356461477e-07, 'adam_beta2': 0.9690451871947846, 'adam_eps': 3.4889766548903616e-08, 'lr_factor': 0.6314950036607717, 'lr_patience': 3, 'clip_norm': 0.9214017645310711, 'label_smoothing': 0.05426960831582485}. Best is trial 0 with value: 0.3391857347216904.\n",
      "[I 2025-08-21 18:22:10,869] Trial 2 finished with value: 0.3271375468351882 and parameters: {'batch_size': 512, 'emb_dim_scale': 1.2434434683002586, 'n_layers': 5, 'width0': 512, 'width1': 256, 'width2': 256, 'width3': 64, 'width4': 256, 'activation': 'GELU', 'use_bn': True, 'use_residuals': True, 'dropout_mlp': 0.21377050917927481, 'dropout_emb': 0.007625738023228556, 'optimizer': 'RMSprop', 'lr': 0.0002913009501549591, 'weight_decay_mlp': 2.3583976885932147e-05, 'weight_decay_emb': 5.280796376895367e-05, 'adam_beta2': 0.9622153192282948, 'adam_eps': 6.618595597183464e-08, 'lr_factor': 0.6022204554172195, 'lr_patience': 3, 'clip_norm': 0.6154698647431895, 'label_smoothing': 0.028975145291376805}. Best is trial 2 with value: 0.3271375468351882.\n",
      "[I 2025-08-21 18:22:34,322] Trial 3 finished with value: 0.3636002306980346 and parameters: {'batch_size': 512, 'emb_dim_scale': 1.0667018782552118, 'n_layers': 6, 'width0': 512, 'width1': 256, 'width2': 512, 'width3': 64, 'width4': 512, 'width5': 256, 'activation': 'ReLU', 'use_bn': False, 'use_residuals': False, 'dropout_mlp': 0.3047821669899484, 'dropout_emb': 0.15080370696865844, 'optimizer': 'RMSprop', 'lr': 0.00022587177280197245, 'weight_decay_mlp': 2.460746712417507e-06, 'weight_decay_emb': 2.940074130903305e-06, 'adam_beta2': 0.9982968722514194, 'adam_eps': 3.048670883458062e-08, 'lr_factor': 0.5688542189623513, 'lr_patience': 5, 'clip_norm': 0.8564563159885995, 'label_smoothing': 0.07282163486118597}. Best is trial 2 with value: 0.3271375468351882.\n",
      "[I 2025-08-21 18:22:45,907] Trial 4 finished with value: 0.36365004423377656 and parameters: {'batch_size': 1024, 'emb_dim_scale': 1.0178873420373793, 'n_layers': 2, 'width0': 128, 'width1': 256, 'activation': 'GELU', 'use_bn': True, 'use_residuals': True, 'dropout_mlp': 0.06876047207299663, 'dropout_emb': 0.10231990531507755, 'optimizer': 'Adam', 'lr': 0.00024044240360019065, 'weight_decay_mlp': 6.043341601953103e-05, 'weight_decay_emb': 2.82921922553619e-05, 'adam_beta2': 0.9772048397683736, 'adam_eps': 1.1463075602213988e-07, 'lr_factor': 0.39674091636018066, 'lr_patience': 2, 'clip_norm': 1.84582363692999, 'label_smoothing': 0.09004180571633305}. Best is trial 2 with value: 0.3271375468351882.\n",
      "[I 2025-08-21 18:22:53,370] Trial 5 pruned. \n",
      "[I 2025-08-21 18:23:17,293] Trial 6 finished with value: 0.32264507100224954 and parameters: {'batch_size': 256, 'emb_dim_scale': 1.2141592812938626, 'n_layers': 4, 'width0': 128, 'width1': 256, 'width2': 256, 'width3': 512, 'activation': 'GELU', 'use_bn': False, 'use_residuals': False, 'dropout_mlp': 0.14679592213224668, 'dropout_emb': 0.24280834664355408, 'optimizer': 'RMSprop', 'lr': 0.0005692653182584713, 'weight_decay_mlp': 2.2572384321973304e-05, 'weight_decay_emb': 2.482478734421257e-05, 'adam_beta2': 0.9818482326081105, 'adam_eps': 2.5347419619497627e-07, 'lr_factor': 0.6183170677744404, 'lr_patience': 6, 'clip_norm': 1.0069927352773038, 'label_smoothing': 0.0375582952639944}. Best is trial 6 with value: 0.32264507100224954.\n",
      "[I 2025-08-21 18:23:35,905] Trial 7 finished with value: 0.3304498328926683 and parameters: {'batch_size': 512, 'emb_dim_scale': 0.9827990090662301, 'n_layers': 4, 'width0': 256, 'width1': 128, 'width2': 128, 'width3': 512, 'activation': 'GELU', 'use_bn': False, 'use_residuals': False, 'dropout_mlp': 0.21948571035281805, 'dropout_emb': 0.023536914402679788, 'optimizer': 'Adam', 'lr': 0.001066690169153495, 'weight_decay_mlp': 1.2698479732927761e-05, 'weight_decay_emb': 3.310418956324512e-07, 'adam_beta2': 0.9576654150908832, 'adam_eps': 3.1658169231879685e-08, 'lr_factor': 0.5196906658824482, 'lr_patience': 5, 'clip_norm': 1.4902960650765968, 'label_smoothing': 0.027993389694594285}. Best is trial 6 with value: 0.32264507100224954.\n",
      "[I 2025-08-21 18:23:41,112] Trial 8 pruned. \n",
      "[I 2025-08-21 18:23:54,970] Trial 9 finished with value: 0.32016617787879365 and parameters: {'batch_size': 512, 'emb_dim_scale': 0.8478955673946482, 'n_layers': 2, 'width0': 128, 'width1': 512, 'activation': 'LeakyReLU', 'leaky_slope': 0.03245131724811469, 'use_bn': False, 'use_residuals': False, 'dropout_mlp': 0.4017404651924243, 'dropout_emb': 0.08461037177139194, 'optimizer': 'RMSprop', 'lr': 0.0029046659796387346, 'weight_decay_mlp': 1.2991004501022528e-05, 'weight_decay_emb': 1.3063340811682283e-06, 'adam_beta2': 0.9880442350763579, 'adam_eps': 4.804045151253041e-08, 'lr_factor': 0.6723029302414258, 'lr_patience': 6, 'clip_norm': 1.1434910410625276, 'label_smoothing': 0.07508710677914975}. Best is trial 9 with value: 0.32016617787879365.\n",
      "[I 2025-08-21 18:24:11,354] Trial 10 finished with value: 0.33103240096417497 and parameters: {'batch_size': 1024, 'emb_dim_scale': 0.7529985914779085, 'n_layers': 3, 'width0': 256, 'width1': 512, 'width2': 512, 'activation': 'LeakyReLU', 'leaky_slope': 0.020798074567397615, 'use_bn': False, 'use_residuals': True, 'dropout_mlp': 0.33912689987562616, 'dropout_emb': 0.07767318985447431, 'optimizer': 'AdamW', 'lr': 0.002918893257204828, 'weight_decay_mlp': 0.00041201399887218177, 'weight_decay_emb': 1.326872183795527e-07, 'adam_beta2': 0.9923917248716531, 'adam_eps': 9.352172523875068e-07, 'lr_factor': 0.6753238030441346, 'lr_patience': 6, 'clip_norm': 1.5480097086745035, 'label_smoothing': 0.06856136739038807}. Best is trial 9 with value: 0.32016617787879365.\n",
      "[I 2025-08-21 18:24:24,408] Trial 11 finished with value: 0.3186073160388972 and parameters: {'batch_size': 256, 'emb_dim_scale': 0.7931844609096352, 'n_layers': 3, 'width0': 128, 'width1': 64, 'width2': 256, 'activation': 'LeakyReLU', 'leaky_slope': 0.06134899459505459, 'use_bn': False, 'use_residuals': False, 'dropout_mlp': 0.012774747405271625, 'dropout_emb': 0.29880678479774386, 'optimizer': 'RMSprop', 'lr': 0.0029802850074114387, 'weight_decay_mlp': 8.877356592915088e-06, 'weight_decay_emb': 6.801192985672223e-06, 'adam_beta2': 0.987191395192289, 'adam_eps': 3.498109413988023e-07, 'lr_factor': 0.6997379725702203, 'lr_patience': 6, 'clip_norm': 1.0667501066902456, 'label_smoothing': 0.040811012506602594}. Best is trial 11 with value: 0.3186073160388972.\n",
      "[I 2025-08-21 18:24:35,976] Trial 12 finished with value: 0.32752238908415016 and parameters: {'batch_size': 256, 'emb_dim_scale': 0.7727831253160888, 'n_layers': 3, 'width0': 128, 'width1': 64, 'width2': 128, 'activation': 'LeakyReLU', 'leaky_slope': 0.052914441662606865, 'use_bn': False, 'use_residuals': False, 'dropout_mlp': 0.0023700598265445905, 'dropout_emb': 0.08251219104371528, 'optimizer': 'RMSprop', 'lr': 0.002799346554846427, 'weight_decay_mlp': 7.677548073804634e-06, 'weight_decay_emb': 5.380808322182501e-06, 'adam_beta2': 0.9859812270929754, 'adam_eps': 4.7080070657464216e-07, 'lr_factor': 0.6657899518906151, 'lr_patience': 6, 'clip_norm': 1.1543092565555528, 'label_smoothing': 0.05628239839186713}. Best is trial 11 with value: 0.3186073160388972.\n",
      "[I 2025-08-21 18:24:47,603] Trial 13 finished with value: 0.3200147238438007 and parameters: {'batch_size': 256, 'emb_dim_scale': 0.872058481623921, 'n_layers': 3, 'width0': 128, 'width1': 64, 'width2': 64, 'activation': 'LeakyReLU', 'leaky_slope': 0.10576012515566925, 'use_bn': False, 'use_residuals': False, 'dropout_mlp': 0.3597303515123649, 'dropout_emb': 0.2828143471413368, 'optimizer': 'RMSprop', 'lr': 0.001602993940959111, 'weight_decay_mlp': 7.539513892706761e-06, 'weight_decay_emb': 2.913166731860168e-06, 'adam_beta2': 0.9881919819132722, 'adam_eps': 3.9324079939477853e-07, 'lr_factor': 0.6973815210564831, 'lr_patience': 6, 'clip_norm': 1.190120219140787, 'label_smoothing': 0.07226414626376901}. Best is trial 11 with value: 0.3186073160388972.\n",
      "[I 2025-08-21 18:24:58,671] Trial 14 finished with value: 0.32102387738267385 and parameters: {'batch_size': 256, 'emb_dim_scale': 0.8739466182042798, 'n_layers': 3, 'width0': 128, 'width1': 64, 'width2': 64, 'activation': 'LeakyReLU', 'leaky_slope': 0.14015205585857657, 'use_bn': False, 'use_residuals': True, 'dropout_mlp': 0.3200058068194079, 'dropout_emb': 0.2955635755836858, 'optimizer': 'RMSprop', 'lr': 0.0014576267150884531, 'weight_decay_mlp': 5.361553261493253e-06, 'weight_decay_emb': 6.1535542519487455e-06, 'adam_beta2': 0.9979324538877135, 'adam_eps': 3.408537034450418e-07, 'lr_factor': 0.45265976463912544, 'lr_patience': 5, 'clip_norm': 1.406081305147177, 'label_smoothing': 0.045563433875952145}. Best is trial 11 with value: 0.3186073160388972.\n",
      "[I 2025-08-21 18:25:09,775] Trial 15 finished with value: 0.3217204592220028 and parameters: {'batch_size': 256, 'emb_dim_scale': 0.8200825321921568, 'n_layers': 3, 'width0': 128, 'width1': 64, 'width2': 64, 'activation': 'LeakyReLU', 'leaky_slope': 0.10811848942523827, 'use_bn': False, 'use_residuals': False, 'dropout_mlp': 0.009156099045255828, 'dropout_emb': 0.2386784961952167, 'optimizer': 'AdamW', 'lr': 0.0016134141918503406, 'weight_decay_mlp': 1.0935754677596584e-06, 'weight_decay_emb': 2.1808146127063645e-06, 'adam_beta2': 0.9511208442331579, 'adam_eps': 8.201450411034137e-07, 'lr_factor': 0.6871013003751493, 'lr_patience': 4, 'clip_norm': 1.63156663178608, 'label_smoothing': 0.00868160541378047}. Best is trial 11 with value: 0.3186073160388972.\n",
      "[I 2025-08-21 18:25:25,939] Trial 16 pruned. \n",
      "[I 2025-08-21 18:25:36,709] Trial 17 finished with value: 0.31864342805164964 and parameters: {'batch_size': 256, 'emb_dim_scale': 0.808511203541344, 'n_layers': 3, 'width0': 128, 'width1': 64, 'width2': 64, 'activation': 'LeakyReLU', 'leaky_slope': 0.18423319420685402, 'use_bn': False, 'use_residuals': False, 'dropout_mlp': 0.2709830559780355, 'dropout_emb': 0.22733719923425214, 'optimizer': 'RMSprop', 'lr': 0.0017643783098559257, 'weight_decay_mlp': 8.338924105527668e-05, 'weight_decay_emb': 1.039660914530597e-06, 'adam_beta2': 0.9925710974974884, 'adam_eps': 1.9160390278476656e-07, 'lr_factor': 0.6969262187414036, 'lr_patience': 5, 'clip_norm': 0.5141936511083818, 'label_smoothing': 0.019646269643510763}. Best is trial 11 with value: 0.3186073160388972.\n",
      "[I 2025-08-21 18:25:51,263] Trial 18 finished with value: 0.32230574363763326 and parameters: {'batch_size': 1024, 'emb_dim_scale': 0.8035538023824018, 'n_layers': 5, 'width0': 128, 'width1': 64, 'width2': 64, 'width3': 256, 'width4': 64, 'activation': 'LeakyReLU', 'leaky_slope': 0.1789032962092723, 'use_bn': True, 'use_residuals': True, 'dropout_mlp': 0.26725434530698183, 'dropout_emb': 0.23518706517013133, 'optimizer': 'AdamW', 'lr': 0.001998203439037657, 'weight_decay_mlp': 0.00012754567219847482, 'weight_decay_emb': 5.460656641594569e-07, 'adam_beta2': 0.9926146433777914, 'adam_eps': 2.2513684623554608e-07, 'lr_factor': 0.6276959258612431, 'lr_patience': 5, 'clip_norm': 0.5333971849715926, 'label_smoothing': 0.01799337432818709}. Best is trial 11 with value: 0.3186073160388972.\n",
      "[I 2025-08-21 18:26:06,116] Trial 19 finished with value: 0.3231919717235154 and parameters: {'batch_size': 256, 'emb_dim_scale': 0.9242516479099356, 'n_layers': 3, 'width0': 256, 'width1': 64, 'width2': 256, 'activation': 'LeakyReLU', 'leaky_slope': 0.19754603480251415, 'use_bn': False, 'use_residuals': False, 'dropout_mlp': 0.15375288901364884, 'dropout_emb': 0.21075504449941537, 'optimizer': 'Adam', 'lr': 0.0008487091671513342, 'weight_decay_mlp': 0.00041707103807654407, 'weight_decay_emb': 1.1632539728790175e-07, 'adam_beta2': 0.983228219382891, 'adam_eps': 1.636413376570751e-07, 'lr_factor': 0.33872924374846647, 'lr_patience': 4, 'clip_norm': 0.6758588441491882, 'label_smoothing': 0.01972660486553757}. Best is trial 11 with value: 0.3186073160388972.\n",
      "Best value (val loss): 0.3186073160388972\n",
      "Best params: {'batch_size': 256, 'emb_dim_scale': 0.7931844609096352, 'n_layers': 3, 'width0': 128, 'width1': 64, 'width2': 256, 'activation': 'LeakyReLU', 'leaky_slope': 0.06134899459505459, 'use_bn': False, 'use_residuals': False, 'dropout_mlp': 0.012774747405271625, 'dropout_emb': 0.29880678479774386, 'optimizer': 'RMSprop', 'lr': 0.0029802850074114387, 'weight_decay_mlp': 8.877356592915088e-06, 'weight_decay_emb': 6.801192985672223e-06, 'adam_beta2': 0.987191395192289, 'adam_eps': 3.498109413988023e-07, 'lr_factor': 0.6997379725702203, 'lr_patience': 6, 'clip_norm': 1.0667501066902456, 'label_smoothing': 0.040811012506602594}\n",
      "Best trial metrics: acc = 0.8532338308457711 auc = 0.9094859169700612\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "def make_loaders(batch_size_train, batch_size_val=None):\n",
    "    if batch_size_val is None:\n",
    "        batch_size_val = max(1024, batch_size_train * 2)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True,  num_workers=0, pin_memory=False)\n",
    "    val_loader   = DataLoader(val_dataset,   batch_size=batch_size_val,   shuffle=False, num_workers=0, pin_memory=False)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def train_one_epoch_opt(model, loader, optimizer, criterion, device, clip_norm=1.0, label_smoothing=0.0):\n",
    "    model.train()\n",
    "    total, n = 0.0, 0\n",
    "    for x_cat, x_num, yb in loader:\n",
    "        x_cat = x_cat.to(device); x_num = x_num.to(device); yb = yb.to(device)\n",
    "        if label_smoothing > 0:\n",
    "            yb = yb * (1.0 - label_smoothing) + 0.5 * label_smoothing\n",
    "        logits = model(x_cat, x_num)\n",
    "        loss = criterion(logits, yb)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip_norm)\n",
    "        optimizer.step()\n",
    "        bs = yb.size(0); total += loss.item() * bs; n += bs\n",
    "    return total / n\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_metrics(model, loader, criterion, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    total, n = 0.0, 0\n",
    "    all_probs, all_targets = [], []\n",
    "    for x_cat, x_num, yb in loader:\n",
    "        x_cat = x_cat.to(device); x_num = x_num.to(device); yb = yb.to(device)\n",
    "        logits = model(x_cat, x_num)\n",
    "        loss = criterion(logits, yb)\n",
    "        bs = yb.size(0); total += loss.item() * bs; n += bs\n",
    "        probs = torch.sigmoid(logits).squeeze(1).cpu().numpy()\n",
    "        targets = yb.squeeze(1).cpu().numpy()\n",
    "        all_probs.append(probs); all_targets.append(targets)\n",
    "    loss = total / n\n",
    "    all_probs = np.concatenate(all_probs)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "    preds = (all_probs >= threshold).astype(np.int32)\n",
    "    acc = accuracy_score(all_targets, preds)\n",
    "    auc = roc_auc_score(all_targets, all_probs) if np.unique(all_targets).size > 1 else float(\"nan\")\n",
    "    return loss, acc, auc\n",
    "\n",
    "def build_model_from_trial(trial, emb_dims_base, n_num):\n",
    "    dim_scale = trial.suggest_float(\"emb_dim_scale\", 0.75, 1.25)\n",
    "    emb_dims = []\n",
    "    for (v, d) in emb_dims_base:\n",
    "        d2 = int(max(4, min(50, round(d * dim_scale))))\n",
    "        emb_dims.append((v, d2))\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 6)\n",
    "    width0 = trial.suggest_categorical(\"width0\", [128, 256, 512])\n",
    "    widths = [width0]\n",
    "    for i in range(1, n_layers):\n",
    "        widths.append(trial.suggest_categorical(f\"width{i}\", [64, 128, 256, 512]))\n",
    "    act_name = trial.suggest_categorical(\"activation\", [\"ReLU\", \"LeakyReLU\", \"GELU\"])\n",
    "    leaky_slope = trial.suggest_float(\"leaky_slope\", 0.01, 0.2) if act_name == \"LeakyReLU\" else 0.01\n",
    "    use_bn = trial.suggest_categorical(\"use_bn\", [False, True])\n",
    "    use_residual = trial.suggest_categorical(\"use_residuals\", [False, True])\n",
    "    p_mlp = trial.suggest_float(\"dropout_mlp\", 0.0, 0.5)\n",
    "    p_emb = trial.suggest_float(\"dropout_emb\", 0.0, 0.3)\n",
    "    model = CatEmbMLPOpt(emb_dims=emb_dims, n_num=n_num, hidden=tuple(widths),\n",
    "                         p_mlp=p_mlp, p_emb=p_emb, use_bn=use_bn,\n",
    "                         act_name=act_name, leaky_slope=leaky_slope,\n",
    "                         use_residuals=use_residual).to(\"cpu\")\n",
    "    return model\n",
    "\n",
    "def make_optimizer_from_trial(trial, model):\n",
    "    opt_name = trial.suggest_categorical(\"optimizer\", [\"AdamW\", \"Adam\", \"RMSprop\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 3e-3, log=True)\n",
    "    wd_mlp = trial.suggest_float(\"weight_decay_mlp\", 1e-6, 5e-4, log=True)\n",
    "    wd_emb = trial.suggest_float(\"weight_decay_emb\", 1e-7, 1e-4, log=True)\n",
    "    beta2 = trial.suggest_float(\"adam_beta2\", 0.95, 0.999)\n",
    "    eps = trial.suggest_float(\"adam_eps\", 1e-8, 1e-6, log=True)\n",
    "    emb_params, mlp_params = [], []\n",
    "    for name, p in model.named_parameters():\n",
    "        if not p.requires_grad: continue\n",
    "        (emb_params if name.startswith(\"embs.\") else mlp_params).append(p)\n",
    "    if opt_name == \"AdamW\":\n",
    "        optimizer = torch.optim.AdamW([{\"params\": emb_params, \"weight_decay\": wd_emb},\n",
    "                                       {\"params\": mlp_params, \"weight_decay\": wd_mlp}],\n",
    "                                       lr=lr, betas=(0.9, beta2), eps=eps)\n",
    "    elif opt_name == \"Adam\":\n",
    "        optimizer = torch.optim.Adam([{\"params\": emb_params, \"weight_decay\": wd_emb},\n",
    "                                      {\"params\": mlp_params, \"weight_decay\": wd_mlp}],\n",
    "                                      lr=lr, betas=(0.9, beta2), eps=eps)\n",
    "    else:\n",
    "        optimizer = torch.optim.RMSprop([{\"params\": emb_params, \"weight_decay\": wd_emb},\n",
    "                                         {\"params\": mlp_params, \"weight_decay\": wd_mlp}],\n",
    "                                         lr=lr, alpha=0.99, eps=eps)\n",
    "    return optimizer\n",
    "\n",
    "def make_scheduler_from_trial(trial, optimizer):\n",
    "    factor = trial.suggest_float(\"lr_factor\", 0.3, 0.7)\n",
    "    patience = trial.suggest_int(\"lr_patience\", 2, 6)\n",
    "    return torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=factor, patience=patience, min_lr=1e-5)\n",
    "\n",
    "def objective(trial):\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [256, 512, 1024])\n",
    "    train_loader, val_loader = make_loaders(batch_size)\n",
    "    model = build_model_from_trial(trial, emb_dims, n_num)\n",
    "    optimizer = make_optimizer_from_trial(trial, model)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    scheduler = make_scheduler_from_trial(trial, optimizer)\n",
    "    clip_norm = trial.suggest_float(\"clip_norm\", 0.5, 2.0)\n",
    "    label_smoothing = trial.suggest_float(\"label_smoothing\", 0.0, 0.1)\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    best_acc, best_auc = 0.0, 0.0\n",
    "    EPOCHS = 25\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        _ = train_one_epoch_opt(model, train_loader, optimizer, criterion, device=\"cpu\",\n",
    "                                clip_norm=clip_norm, label_smoothing=label_smoothing)\n",
    "        va_loss, va_acc, va_auc = eval_metrics(model, val_loader, criterion, device=\"cpu\")\n",
    "        scheduler.step(va_loss)\n",
    "        trial.report(va_loss, step=epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "        if va_loss < best_val:\n",
    "            best_val, best_acc, best_auc = va_loss, va_acc, va_auc\n",
    "\n",
    "    trial.set_user_attr(\"best_val_loss\", float(best_val))\n",
    "    trial.set_user_attr(\"best_acc\", float(best_acc))\n",
    "    trial.set_user_attr(\"best_auc\", float(best_auc))\n",
    "    return best_val\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=TPESampler(seed=42), pruner=MedianPruner(n_startup_trials=5, n_warmup_steps=5))\n",
    "study.optimize(objective, n_trials=20, show_progress_bar=True)\n",
    "\n",
    "bt = study.best_trial\n",
    "print(\"Best value (val loss):\", study.best_value)\n",
    "print(\"Best params:\", bt.params)\n",
    "print(\"Best trial metrics: acc =\", bt.user_attrs.get(\"best_acc\"), \"auc =\", bt.user_attrs.get(\"best_auc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb06494e-6a2d-498b-ad53-6fe5068da53c",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "62254aa4-6991-4bdc-94b9-4035497b0ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x351f173b0>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "probs = torch.sigmoid(model(torch.tensor(X_val_categories, dtype=torch.long),\n",
    "                            torch.tensor(X_val_scaled, dtype=torch.float32))).detach().numpy().squeeze()\n",
    "preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_val, preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "                      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a357440-177b-4008-b55e-b84d4165e7c3",
   "metadata": {},
   "source": [
    "# Reflection\n",
    "\n",
    "This project went really well in terms of building a full end-to-end pipeline. I was able to set up preprocessing, a custom Dataset and DataLoader, the model, the loss and optimizer, a training loop with early stopping and a learning rate scheduler, and then track metrics properly. Along the way, I developed a much clearer mental model of key PyTorch concepts like logits vs. probabilities, why BCEWithLogitsLoss is preferred, the role of .train() and .eval(), device transfers, batch sizing, and how to aggregate batch metrics. I also handled categorical embeddings correctly, with per-column vocabularies and UNK handling, and built some debugging intuition by catching NaNs during initialization and tracing them back to Apple GPU issues. On top of that, I established a strong baseline by running XGBoost and comparing it to the neural network.\n",
    "\n",
    "What didn’t go so smoothly was that the validation loss plateaued at around 0.307, regardless of scheduler tweaks or learning rate changes. This turned out not to be a problem with optimization but more a sign of architectural capacity limits in the MLP. Using Apple’s MPS backend also caused NaN issues, which forced me back to CPU training for stability. I also leaned a little too quickly on Optuna, when in hindsight the flat validation curve indicated that I should have tried architectural changes or regularization adjustments first.\n",
    "\n",
    "The main lessons I’m taking away are that preprocessing must be done carefully to avoid leakage, embeddings help compress sparse categorical data into useful representations, and schedulers should always monitor validation performance, not just training. I also learned it’s often better to slightly over-parameterize a network and regularize it than to under-parameterize and cap performance. XGBoost slightly outperformed the neural network here, which is expected in tabular settings because trees are so good at capturing threshold-like interactions that MLPs miss without more advanced architectures.\n",
    "\n",
    "If I were to run this again, I would try a larger MLP with batch normalization and lighter dropout, experiment with more dynamic learning rate schedules like OneCycle, and consider using pos_weight in the loss if the classes are imbalanced. I’d also look at engineered interaction features to see if the neural net can learn from what boosts XGBoost. For a bigger leap, I’d try transformer-style tabular models like FT-Transformer and compare them against XGBoost on a larger dataset. Overall, the biggest win is that I now have a clean, reusable training loop, a dataset pipeline, a hyperparameter tuning scaffold, and a strong baseline comparison — all of which I can carry into my next project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ce93de-2c0b-4d9c-b420-6476c35a2b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
